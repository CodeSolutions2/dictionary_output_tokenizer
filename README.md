# tokenizer

The purpose of this repository is to demonstrate/compare different ways to tokenize text, for text classification and/or generation.

[Current working version of word tokenization] https://codesolutions2.github.io/tokenizer/index2.html


## In progress
  - A more rigorous version of the word tokenizer
  - Subword tokenization

## Regex usage for Tokenization
Regex is a powerful library that can be used to preprocess text strings. These JavaScript tokenizers use regex to process text. Similarly, Regex can be used in Python to tokenize text.
- Usage of Regex for Tokenization: https://medium.com/@j622amilah/wonders-of-regex-834f255805fe
