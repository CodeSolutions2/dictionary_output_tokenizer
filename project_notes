// Index

Tokenizer








// Try 0: Works!
		// outp.innerHTML += 'rowdata: ' + rowdata + "<br/>";
		// outp.innerHTML += 'index: ' + index + "<br/>";

		// Initially determined the name of the dictionary keys and values - valueNames: xs,ys
		// if (index == 0) { const valueNames = Object.keys(rowdata); outp.innerHTML += 'valueNames: ' + valueNames + "<br/>";}

		// X = tf.tensor(Object.values(rowdata.xs));
		// Y = tf.tensor(Object.values(rowdata.ys));

		// OR
		
		// The value of X and Y does not change per rowdata
		// X = await Object.values(rowdata.xs).toString();
		// Y = await Object.values(rowdata.ys).toString();

		 // Convert string tensor to javascript tensor
		 // X = X.toString();
		 // Y = Y.toString();


  // -------------------------------------------------
// How to read rows from a csvDataset
  // -------------------------------------------------

// Way 0 
// This is an object, and can iterate over values in the Object
const csv_iterator = await csvDataset.iterator();
	  
	  const tensors = await csvDataset.toArray();
tensors.forEach(async function(rowdata, index) {

	await csv_iterator.next().then(row => {

	      // row is [object Object] for Try 1 and 2
	     // outp.innerHTML += 'row: ' + row + "<br/>";
		  
	});  // end of await csv_iterator.next().then(row =>

});  // end of forEach


// -------------------------------------------------


// Way 1
// Same output as csvDataset, so just using csvDataset directly
// This is an object, and can iterate over values in the Object
const flattenedDataset = await csvDataset.map(({xs, ys}) => { return {xs:Object.values(xs), ys:Object.values(ys)}; });
// outp.innerHTML += 'flattenedDataset: ' +  flattenedDataset + "<br/>";
const csv_iterator_values = await flattenedDataset.iterator()
   
// This is an object, and can iterate over values in the Object
const csv_iterator = await csvDataset.iterator();
	  
const tensors = await csvDataset.toArray();
tensors.forEach(async function(rowdata, index) {

await csv_iterator_values.next().then(row => {
		
	      // row is [object Object] for Try 1 and 2
	     // outp.innerHTML += 'row: ' + row + "<br/>";
		  
	});  // end of await csv_iterator.next().then(row =>

});  // end of forEach


// -------------------------------------------------

# ---------------------------------------------
# Set up dataset in STORAGE
# ---------------------------------------------
PROJECT_ID="text-pr0cessing"
# ---------------------------------------------
gcloud projects create $PROJECT_ID
# ---------------------------------------------
gcloud config set project $PROJECT_ID
# ---------------------------------------------
# Enable project billing
# Obtain ACCOUNT_ID
gcloud alpha billing accounts list

ACCOUNT_ID=""

# Enable project billing
gcloud alpha billing accounts projects link $PROJECT_ID --billing-account=$ACCOUNT_ID

# View details about billing account
gcloud beta billing accounts describe $ACCOUNT_ID

# ---------------------------------------------

# Create Storage Bucket
BUCKET_NAME="textclassification-w-labeled-data"

LOCATION="europe-west9"
gcloud storage buckets create gs://$BUCKET_NAME --project=$PROJECT_ID \
                                                --default-storage-class=STANDARD \
                                                --location=$LOCATION \
                                                --uniform-bucket-level-access


git clone https://github.com/CodeSolutions2/text_classification_w_labels.git

# Upload file to storage
gcloud storage cp train_dataset0.csv gs://$BUCKET_NAME

gcloud storage ls --recursive gs://$BUCKET_NAME/**

# Make all objects in a bucket publicly readable
gcloud storage buckets add-iam-policy-binding gs://$BUCKET_NAME --member=allUsers --role=roles/storage.objectViewer

# ---------------------------------------------

touch cors.json

echo '[{"origin": ["https://yourdomain.com"],"responseHeader": ["Content-Type"],"method": ["GET", "HEAD"],"maxAgeSeconds": 3600}]' > cors.json

# OR

%%bash --err null
cat > cors.json <<EOF
[
    {
      "origin": ["https://CodeSolutions2.github.io"],
      "responseHeader": ["Content-Type"],
      "method": ["GET", "HEAD"],
      "maxAgeSeconds": 3600
    }
]
EOF

# Set CORS settings
gsutil cors set cors.json gs://$BUCKET_NAME

# ---------------------------------------------

# View saved CORS settings
gsutil cors get gs://$BUCKET_NAME

# ---------------------------------------------


https://cloud.google.com/storage/docs/gsutil/commands/cors

https://stackoverflow.com/questions/66050356/unable-to-fix-cors-policy-on-google-cloud-storage?rq=3

https://stackoverflow.com/questions/51615809/tensorflow-model-server-access-control-allow-origin?rq=3

https://stackoverflow.com/questions/57118200/tensorflowjs-google-storage-cors-error-with-tf-loadlayersmodel







// ---------------------------------------------
// Tokenizer
// ---------------------------------------------
  
// Make an array with word length
let len_X_array = [];
uniqueArray.forEach(async function(word, ind) { len_X_array.push(word.length); });

console.log("len_X_array: " + len_X_array);

// ---------------------------------------------


// -----------
// Way 0 : words with the same length will be assigned the same index
// -----------
// Sort the attribute vector
// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort
// let len_X_array_sort = len_X_array.sort();
// console.log('len_X_array_sort:' + len_X_array_sort);

// Put the attribute vector into a dictionary with a corresponding index
// const dictt = Object.fromEntries(len_X_array_sort.map((atr2sort, index) => [atr2sort, index]));

// Make an array of zeros
//  let X_array_sorted = [...Array(uniqueArray.length).keys()].map((x) => 0);
  
//  uniqueArray.forEach(async function(word, ind) { 

	// word is in position ind=0 of X_array
//         let key = word.length;  // the attribute to sort
       
       // this gives me the index that X_array[word] should have in the output list X_array_sorted
//        let ind_sorted = dictt[key];

       // Print first 10 to see if correct
//        if (ind < 10){ console.log('word:' + word); console.log('key:' + key); console.log('ind_sorted:' + ind_sorted); }
       
       // but, word should be in position ind_sorted
//        X_array_sorted[ind_sorted] = word;
//  });

//  console.log('tokenizer0_X_array_sorted:' + X_array_sorted);

// Write a dictionary, where word=keys are ordered from longest word to shortest word.
// Thus, the longest word has the smallest index, and the shortest word has the largest index.

// var tokenizer0 = Object.fromEntries(X_array_sorted.map((word, index) => [word, index]));
  
// ---------------------------------------------

// -----------
// Way 1
// -----------

async function create_tokenizer_array_w_dict_per_row(uniqueArray) {

	// ------------------------------------------

	// Print the first 5 rows of an array
	uniqueArray.forEach(async function(row, ind) {
		// Print the first 5 key and value pairs
		if (ind < 5){ console.log( 'uniqueArray['+ ind + ']: ' + row ); }
		
	});
	  
	// ------------------------------------------

	// [0] Make an array, where each row is a dictionary where the keys are called name and value; name=word and value=word.length
	var array_w_dictionary_rows = [];
	uniqueArray.forEach(async function(word, ind) { 
		array_w_dictionary_rows.push({ name: word, value: word.length });
	});

	// ------------------------------------------

	// Print the first 5 rows of the array, array_w_dictionary_rows
	console.log('array_w_dictionary_rows:');
	print_an_array_containing_a_dictionary(array_w_dictionary_rows);
	  
	// ------------------------------------------
	
	// [1] Sort an array, containing a dictionary per row, where all the rows are sorted by the dictionary key called value in ascending order.
	// Sorting array of objects: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort
	var ascending_sorted_array = array_w_dictionary_rows.sort((a, b) => a.value - b.value);
	
	// ------------------------------------------
	  
	// Print the first 5 rows of the array, ascending_sorted_array
	console.log('ascending_sorted_array:');
	print_an_array_containing_a_dictionary(ascending_sorted_array);

	// ------------------------------------------

	// [2] Make the array be sorted in descending order, where all the rows are sorted by the dictionary key called value in descending order.
	var descending_sorted_array_w_dictionary_per_row = ascending_sorted_array.reverse();
	  
	// ------------------------------------------
	  
	// Print the first 5 rows of the array, descending_sorted_array_w_dictionary_per_row
	console.log('descending_sorted_array_w_dictionary_per_row:');
	print_an_array_containing_a_dictionary(descending_sorted_array_w_dictionary_per_row);

	// ------------------------------------------

	// [3] Reassign the number in the dictionary key called value, to a increasing count, per row of the descending sorted array
	var out_final = [];
	descending_sorted_array_w_dictionary_per_row.forEach(async function(row, ind) {

		let key = Object.values(row.name).toString();   // This prints the dictionary key per row 
		// let value = Object.values(row.value).toString(); // This prints the dictionary value per row

		// ---------------------
		
		// Try 0
		// descending_sorted_array_w_dictionary_per_row[ind] = {name: key, value: ind}; // This assigns name and value to the key using the number ind

		// Try 1
		// Want to reassign the dictionary value, using the key, per row
		// out_final[key] = ind;

		// Try 2
		
		out_final.push({name: key, value: ind})
	});

	// ------------------------------------------

	// Print the first 5 rows of the array, out_final
	console.log('out_final:');
	print_an_array_containing_a_dictionary(out_final);

	// ------------------------------------------

	  return out_final;
  }

	
  // -------------------------------------------------

	
  async function print_an_array_containing_a_dictionary(array) {
	  
	// Print the first 5 rows of an array, where each row contains a dictionary
	array.forEach(async function(row, ind) {
		
		// Print the available keys of the dictionary
		let list_the_keys_of_the_dict = Object.keys(row).toString();
		console.log( 'list_the_keys_of_the_dict: ' + list_the_keys_of_the_dict );
		// This returns: name,value

		// It is CORRECT sort of, but it prints commas in between each letter
		let key = Object.values(row.name);   // It should print the dictionary key per array row
		// OR
		let key1 = array[ind].toString();  // It prints [Object] object

		// It is INCORRECT, it prints nothing
		let value = Object.values(row.value); // It should print the dictionary value per array row

		// Print the first 5 key and value pairs
		if (ind < 5){ console.log( 'key: ' + key + ', key1: ' + key1 + ', value:' + value ); }
		
	});

  }

// ---------------------------------------------


    // Way 0: load pre-trained model
    // const MODEL_URL = 'model.json';
    // const custom_model = await tf.loadLayersModel(MODEL_URL);

    // OR

    // Way 1: load model layers using sequential
    
		// let model = tf.sequential();
		// model.add( tf.layers.embedding(inputDim=NUM_WORDS, outputDim=EMBEDDING_DIM, inputLength=MAXLEN) );
		// model.add( tf.layers.globalAveragePooling1d() );
		// model.add( tf.layers.dense(NUM_OF_CLASSES, activation='softmax') );

		// OR

	 // Way 2: load model layers using sequential
		let model = tf.sequential({layers: [tf.layers.embedding(inputDim=NUM_WORDS, outputDim=EMBEDDING_DIM, inputLength=MAXLEN), tf.layers.globalAveragePooling1d(), tf.layers.dense(NUM_OF_CLASSES, activation='softmax')]});
	 
		// Way 3: load model layers using functional API
		// const input = tf.input({shape: [5]});
	 // let Layer0 = tf.layers.embedding(inputDim=NUM_WORDS, outputDim=EMBEDDING_DIM, inputLength=MAXLEN);
	 // let Layer1 = tf.layers.globalAveragePooling1d();
	 // let Layer2 = tf.layers.dense(NUM_OF_CLASSES, activation='softmax');
		// const output = Layer2.apply(Layer1.apply(Layer0.apply(input)));
	 // const model = tf.model({inputs: input, outputs: output});
	
		// ---------------------------

		model.compile({optimizer: 'adam', loss: 'sparse_categorical_crossentropy', metrics: ["accuracy"]});
		

// ---------------------------------------------


	  
    // Number of columns
    // const num_of_cols = (await csvDataset.columnNames()).length;
    // outp.innerHTML += 'num_of_cols: ' + num_of_cols + "<br/>";

    // const column_names = (await csvDataset.columnNames());
    // outp.innerHTML += 'column_names: ' + column_names + "<br/>";

// ---------------------------------------------

  // Create a csvDataset using ONLY the correctly tokenized rows
	  // put x_clean and ys arrays in to a list of dictionaries per row with the same keys
	  // data should look like : [{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13}, ...]
	  let data = []; 
	  correctly_tokenized_rows.forEach(async function(correct_ind, ind) { 

		let xs_seq_correct_row = xs_seq[correct_ind];
		  
		  
		// Post pad the sequences such that each sequence is [1, maxlen_local], or xs_seq is size [num_of_rows, maxlen_local]
		let amount2pad = maxlen_local - xs_seq_correct_row.length; // OK
		let array_of_zeros = Array.from({ length: amount2pad }, (_, i) => 0);
		let xs_seq_pad = xs_seq_correct_row.concat(array_of_zeros);

		// Does not print for some reason
		// if (ind == 0){
		// 	console.log("maxlen_local: " + maxlen_local);
		// 	console.log("xs_seq_correct_row.length: " + xs_seq_correct_row.length);
		// 	console.log("amount2pad: " + amount2pad);
			
		// 	console.log("xs_seq_correct_row: " + xs_seq_correct_row);
		// 	console.log("array_of_zeros: " + array_of_zeros);
		// 	console.log("xs_seq_pad: " + concatenated_array1);
		// }
		  
		// data.push({xs: xs_seq_pad, ys: ys[correct_ind]}); 
		data.push({xs: xs_seq[correct_ind], ys: ys[correct_ind]}); 
	  });
	
	  const  = await tf.data.array(data).batch(1);  // Output:  Returns: tf.data.Dataset 


// ---------------------------------------------


// ---------------------------------------------


// ---------------------------------------------


// ---------------------------------------------

// ---------------------------------------------

// ---------------------------------------------


// ---------------------------------------------

// ---------------------------------------------


// ---------------------------------------------





Ideas

0. use local Storage to save maxlen

1. add and Event listener for the change of value for maxlen, then update global variable

2. There is not guarantee that the 2 forEach statements will run in sequenqtial order - so add async/await to these two

// ---------------------------------------------


Design0 : this has too many sublevels I think
async train_model
	- await get_csvDataset ---> csvDataset
	- await modify_X_Y ---> csvDataset_sequence
		- await find_class_names ---> class_names (updates global variable)
		- tensors.forEach ---> xs, ys (NO await used)
		- await tokenize_X(xs, ys) 
			- xs_rest.forEach --> final_str (NO await used)
			- tokenizer = await create_tokenizer_dict(uniqueArray)
			- vocab_size = await update_global_variable_vocab_size(tokenizer) (updates global variable)
			- csvDataset_sequence = await apply_tokenizer_to_sentences(xs, ys, tokenizer)
				- xs.forEach --> xs_seq, maxlen_local, correctly_tokenized_rows (NO await used)
				- correctly_tokenized_rows.forEach --> csvDataset_sequence (NO await used)
	- await csvDataset_sequence.map
	- await synchronize_model_parameters

		

const tensors = await csvDataset.toArray();

tensors.forEach(async function(rowdata, index) {

	X = Object.values(rowdata.xs);
	Y = Object.values(rowdata.ys);
	console.log("X: " + X);
	console.log("Y: " + Y);

});  // end of forEach


// ---------------------------------------------




