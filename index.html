<!DOCTYPE html>
<html>
<head></head>
<body>

<!-- Text classification webapp -->
<!-- https://js.tensorflow.org/api/1.0.0/ -->
<h1 style='text-align: center; margin-bottom: -35px;'>Text classification webapp</h1>
<br><br>

<!-- [Step 0] Train model -->
<label for="train_dataset_url_label" style="display:block">Enter train dataset location url: url can be Github or GCP storage (ie: https://github.com/CodeSolutions2/text_classification_w_labels/train_dataset.csv):</label>
<input type="text" value="" placeholder="Train dataset url" id="train_dataset_url" rows="1" cols="500" style="display:block">
<br>
<button id="train_model" onclick="train_model()" style="display:block">train_model</button>

	
<!-- [Step 1] Result: say if model is trained or not -->
<div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

	
<!-- [Step 2] -->
<!-- https://developer.mozilla.org/en-US/docs/Web/CSS/position -->
<style>
canvas {border: 1px solid black; position: absolute; display: inline-block; z-index: 1; top: 150px;},
div {position: relative; z-index: 2;},
table {border-collapse: collapse;}
td,
th {border: 1px solid black; padding: 10px 20px;}
</style>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>

<script>

  // -------------------------------------------------
	
  const outp = document.getElementById('output');

  var url_vec = [];  // This is a global variable, and I start referencing it in get_train_dataset

  // -------------------------------------------------
	
async function get_train_datasetURL() {

	// https://github.com/CodeSolutions2/text_classification_w_labels/train_dataset.csv
	// https://storage.googleapis.com/BUCKET_NAME/train_dataset.csv
	const datasetUrl = document.getElementById("train_dataset_url").value;

	let out = datasetUrl.split("/")

	outp.innerHTML += "out: " + out;
	
	let domain_name = out[2];
	
	if (domain_name == 'github.com'){
		const repoOwner = out[3];
		const repoName = out[4];

		outp.innerHTML += "repoOwner: " + repoOwner;
		outp.innerHTML += "repoName: " + repoName;
		
		var url = `https://api.github.com/repos/${repoOwner}/${repoName}/contents`;
		    //var options = {method : 'get', headers: headers, mode: 'no-cors'};
		    await fetch(url).then(res => res.json()).then(data => {
		    data.forEach(file => {
		      if (file.type === 'file' && file.name.match(/.(csv|txt)$/i)) {
		        
		        //outp.innerHTML += "Filename=" + file.name + ", file url=" + file.download_url + "<br/>";
			url_vec.push(file.download_url);
		      }
		    });
		  }).catch(error => { outp.innerHTML += error; });

	} else if (domain_name == 'storage.googleapis.com') {
		url_vec.push(datasetUrl);
		
	} else {
		outp.innerHTML = 'Please enter a GitHub repository or Google Cloud Platform Storage URL';
	}
	
 
	return url_vec;
}


  // -------------------------------------------------
	

//async function load_model(){

	// Did not work
 	// model = await mobilenet.load().then(model => { return model });
	// OR
	//return await mobilenet.load();
//}
//const model = load_model();
	//TypeError: model.classify is not a function
	
  // -------------------------------------------------

	
  async function train_model() {

    // ---------------------------

    // [Step 0] Read in url
    var url_vec = await get_train_datasetURL();
    // outp.innerHTML += 'url_vec: ' + url_vec + "<br/>";


    // ---------------------------
	  
    // [Step 1] Load custom model 
    // Way 0: load pre-trained model
    // const MODEL_URL = 'https://storage.googleapis.com/tensorflowjsmodels0/model.json';
    // const MODEL_URL = 'model.json';
    // const custom_model = await tf.loadLayersModel(MODEL_URL);

    // OR

    // Way 1: load model layers using sequential
    const custom_model = tf.sequential();
    custom_model.add( tf.layers.embedding(inputDim=NUM_WORDS, outputDim=EMBEDDING_DIM, inputLength=MAXLEN) );
    custom_model.add( tf.layers.globalAveragePooling1d() );
    custom_model.add( tf.layers.dense(num_of_classes, activation='softmax') );

    // OR

    // Way 2: load model layers using functional API (tf.LayersModel)
	  
    // ---------------------------

    custom_model.compile({optimizer='adam', loss='sparse_categorical_crossentropy', metrics=["accuracy"]});
	  
    // ---------------------------
	  
    // [Step 2] Load data into model
    // url_vec.forEach(function(csvUrl, index) {

    // Does not make sense to train the model for every dataset found.
    // It makes more sense to train the model on one seleccted dataset, then test it with predictions.

    // ---------------------------
	  
    // X and y use a flattenedDataset (a dataset object)
    const csvDataset = tf.data.csv(csvUrl, {
	    columnConfigs: {
	    Y: {isLabel: true}
	    }
    });

	    
    // X and y (manually)
	    
    // ---------------------------
	  
    // Number of features is the number of column names minus one for the label column.
    const numOfFeatures = (await csvDataset.columnNames()).length - 1;

    // Prepare the Dataset for training.
    const flattenedDataset = csvDataset.map(({X, Y}) => {
         // Convert rows from object form (keyed by column name) to array form.
         return {X:Object.values(X), Y:Object.values(Y)};
       }).batch(1);

    // });  // end of forEach
	
    // ---------------------------

    // [Step 3] Load data into model

    // ---------------------------

}  // end of train_model

	
  // -------------------------------------------------

	
  async function train_model() {
    
    var pred_vec = [['', '', '', '', ''],['image_name', 'mobilenet_label', 'mobilenet_probability', 'edgeDetection_label', 'edgeDetection_probability']]; // This is a variable for this function only to accumulate the image labels. The model output is trapped inside image.onload, maybe due to the async () function.

    // Call the custom_model 
            const result = custom_model.predict(resizedTensor); 
	    // outp.innerHTML = result.mean();
			
	    // Get probability value as a number
	    const resultData = await result.data(); // correct

//


	  
	  
    await custom_model.predict(resizedTensor).then(predictions => { 


	    
				// outp.innerHTML += predictions[0].className + " : " + predictions[0].probability + "<br/>";

				pred_vec.push([image_name, predictions[0].className, predictions[0].probability, '', '']);
				// data accumulates correctly in pred_vec, here:
				// outp.innerHTML += 'pred_vec: ' + pred_vec + "<br/>";
									});

		    	// Call Model 1: edge_detection_model
		    	await run_group_together(image, custom_model).then(datavec => { 
				pred_vec[index+2][3] = datavec[0][0];  // label name
				pred_vec[index+2][4] = datavec[0][1];  // probability
									});
		    	
		    	// Save accumulated array as csv file at the last url entry
		    	if (index == url_vec.length-1) {
				// data accumulates correctly in pred_vec, here:
				// outp.innerHTML += 'pred_vec: ' + pred_vec + "<br/>";
				
				// Save array to csv and put download csv file link on screen (NO AUTOMATIC DOWNLOADING)
				await put_results_in_CSVfile(pred_vec);

				// Create a table dynamically with the results
				await generateTable_dynamically(pred_vec);
			}
	  

	    // pred_vec is not defined here
		

}  // end of train_model

	
  // -------------------------------------------------

  async function put_results_in_CSVfile(pred_vec) {
    
    // ---------------------
    // Puts array into csv format
    const blob = new Blob([pred_vec], { type: 'text/csv;charset=utf-8;' });

    // Create a url for the data object
    const url = URL.createObjectURL(blob);
    // ---------------------
    // OR
    // ---------------------
    // Puts array into csv format
    // let csvContent = "data:text/csv; charset=utf-8";
    // pred_vec.forEach(function(row_array) {
	// csvContent += row_array.join(",") + "\r\n";
    // });
    // OR
    // let csvContent = "data:text/csv;charset=utf-8," + rows.map(e => e.join(",")).join("\n");
	  
    // Create a url for the data object
    // var url = encodeURI(csvContent);
    // ---------------------

    const link = document.createElement("a");
    link.setAttribute("href", url);

    const filename = 'data.csv';
    link.setAttribute("download", filename);
	  
    link.style.display = 'block';

    outp.innerHTML += 'Download CSV here: ' + url + "<br/>";
    // document.body.appendChild(link);

    // Automatic download of csv
    // link.click();
    // document.body.removeChild(link);
	  
}

  // -------------------------------------------------

  async function generateTable_dynamically(pred_vec) {

  	const tbl = document.createElement("table");
  
  	const tblBody = document.createElement("tbody");
  
  	// Create row cells dynamically
  	for (let i=0; i < pred_vec.length; i++){
  		// create a table row
  		const row = document.createElement("tr");
  
  		for (let j=0; j < pred_vec[0].length; j++){
  			const cell = document.createElement("td");
  			const cellText = document.createTextNode(`${pred_vec[i][j]}`);
  			cell.appendChild(cellText);
  			row.appendChild(cell);
  		}
  
  		// add a row to the end of the table
  		tblBody.appendChild(row);
  	}
  	tbl.appendChild(tblBody);
  
  	document.body.appendChild(tbl);

  }  

  // -------------------------------------------------


  async function run_group_together(image, edgeDetection_model) {
	  
    // https://github.com/tensorflow/tfjs-models/tree/master/mobilenet
    const datavec = [];
	  
    try {
	// ---------------------
	// For using an image input to mobilenet
	// ---------------------
	// await model.classify(image).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].className + " : " + predictions[i].probability;} }); 
	// OR
	// Just list the first prediction choice, use a tensor as input
	// await model.classify(image).then(predictions => { outp.innerHTML += predictions[0].className + " : " + predictions[0].probability + "<br/>"; pred_vec.push([predictions[0].className, predictions[0].probability]); });
	    
	// ---------------------
	// For using a tensor input to mobilenet
	// ---------------------
	// Convert the image element to a tensor using fromPixels
	// var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3

	// View the largest pixel value
	// outp.innerHTML += tf.max(tensor_image) + "<br/>";
	
	// const eTensor = tensor_image.expandDims(0); // This is size 1,224,224,3
	// outp.innerHTML += eTensor.shape + "<br/>";
	// ---------------------
	    
	// await model.classify(eTensor).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].className + " : " + predictions[i].probability;} }); 
	// OR
	// Just list the first prediction choice, use a tensor as input
	// await model.classify(eTensor).then(predictions => { outp.innerHTML += predictions[0].className + " : " + predictions[0].probability + "<br/>"; pred_vec.push([predictions[0].className, predictions[0].probability]); });
	// OR
	// Print the first prediction choice, use an image as input
	// await mobilenet.load().then(model => {model.classify(eTensor).then(predictions => { outp.innerHTML += predictions[0].className + " : " + predictions[0].probability + "<br/>"; } ) });


	// ---------------------
	// Using a tensor input to edgeDetection_model
	// ---------------------
	// Convert the image element to a tensor using fromPixels
	var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
	    
	const k_rgb_values = tf.tensor4d([[[[ 1000.], [ 1000.], [ 1000.]],[[    0.], [    0.], [    0.]],[[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]]], shape=[3, 3, 3, 1], dtype='float32');
		  
	const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3
	const image_4D_float = tf.cast(image_4D, 'float32')
	const image_filter0 = tf.conv2d(image_4D_float, k_rgb_values, 1, 'same') 

	// Dispose of the intermediate tensors
	tensor_image.dispose();
	k_rgb_values.dispose();
	image_4D.dispose();
	image_4D_float.dispose();
		  
	// Make image values from -1 to 1
            const b = tf.scalar(255);
	    const image_filter = image_filter0.div(b)
	    const shape_out = image_filter.shape;   // 1,276,250,1

            // Dispose of the intermediate tensors
            image_filter0.dispose();
            b.dispose();

            // Ensure that tensor is 4d
            const x = tf.reshape(image_filter, [1, shape_out[1], shape_out[2], shape_out[3]])
            const boxes = tf.tensor2d([[0, 0, 1, 1]], [1, 4]);
            const boxIndices = tf.tensor1d([0], 'int32');
            const newSize = [512, 512];
            const resizedTensor = tf.image.cropAndResize(x, boxes, boxIndices, newSize);
		  
            // Give image to model
            const result = edgeDetection_model.predict(resizedTensor); 
	    // outp.innerHTML = result.mean();
			
	    // Get probability value as a number
	    const resultData = await result.data(); // correct
	    
	    if (resultData > 0.5){
		datavec.push(['apple', resultData]);
	    } else {
		datavec.push(['tomatoe', resultData]);
	    }
	    // outp.innerHTML += "datavec: " + datavec + "<br/>";;
	    
    } catch (error) {
      outp.innerHTML = error; 
    }

	  return datavec;
  } 

  
  // -------------------------------------------------
	
</script>
</body>
</html>
